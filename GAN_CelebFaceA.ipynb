{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SIDDHARTHALODHA_BATCH_7_Assignment4B.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/siddharthalodha/mlsid/blob/master/GAN_CelebFaceA.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "K70hAckqg0EA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "91d00583-f397-4e72-ddbe-d4cf4bb1e830"
      },
      "cell_type": "code",
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "wVIx_KIigxPV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "outputId": "d2588acb-0c4b-40e0-c114-221b99b20122"
      },
      "cell_type": "code",
      "source": [
        "#@title Default title text\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,SeparableConv2D\n",
        "from keras.layers import Concatenate\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.regularizers import l2\n",
        "\n",
        "!wget https://raw.githubusercontent.com/Zahlii/colab-tf-utils/master/utils.py\n",
        "import utils\n",
        "import os"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-05-26 19:25:54--  https://raw.githubusercontent.com/Zahlii/colab-tf-utils/master/utils.py\r\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.52.133\r\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.52.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6935 (6.8K) [text/plain]\n",
            "Saving to: ‘utils.py’\n",
            "\n",
            "utils.py            100%[===================>]   6.77K  --.-KB/s    in 0s      \n",
            "\n",
            "2018-05-26 19:25:54 (59.2 MB/s) - ‘utils.py’ saved [6935/6935]\n",
            "\n",
            "Collecting tqdm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/24/6ab1df969db228aed36a648a8959d1027099ce45fad67532b9673d533318/tqdm-4.23.4-py2.py3-none-any.whl (42kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 3.6MB/s \n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "Successfully installed tqdm-4.23.4\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.1.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.7.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.14.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.12)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.11.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (0.19.1)\n",
            "rm: cannot remove 'tboard.py': No such file or directory\n",
            "--2018-05-26 19:26:01--  https://raw.githubusercontent.com/mixuala/colab_utils/master/tboard.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.52.133\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.52.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5214 (5.1K) [text/plain]\n",
            "Saving to: ‘tboard.py’\n",
            "\n",
            "tboard.py           100%[===================>]   5.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2018-05-26 19:26:01 (57.3 MB/s) - ‘tboard.py’ saved [5214/5214]\n",
            "\n",
            "calling wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip ...\n",
            "calling unzip ngrok-stable-linux-amd64.zip ...\n",
            "ngrok installed. path=/content/ngrok\n",
            "status: tensorboard=False, ngrok=False\n",
            "tensorboard url= http://702ea065.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UNHw6luQg3gc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9793d79a-14ea-4d93-fe17-2f1c157f8477"
      },
      "cell_type": "code",
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "stnxkxDVddRy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "l = 20\n",
        "num_filter =20\n",
        "compression = 0.6\n",
        "dropout_rate = 0.2\n",
        "weight_decay=1e-4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mB7o3zu1g6eT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7a2742cb-b4e2-4edb-c7a5-0f0bee2b818a"
      },
      "cell_type": "code",
      "source": [
        "# Load CIFAR10 Data\n",
        "\n",
        "#http://pjreddie.com/media/files/cifar.tgz\n",
        "#https://web.archive.org/web/20180521182753/https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "\t\n",
        "# finally converting list into numpy array\n",
        "x_train = np.array(x_train)\n",
        "x_test = np.array(x_test)\n",
        "\n",
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "148643840/170498071 [=========================>....] - ETA: 6s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "170500096/170498071 [==============================] - 47s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ee-sge5Kg7vr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Dense Block\n",
        "def add_denseblock(input, num_filter, dropout_rate,l):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l):\n",
        "        BatchNorm = BatchNormalization()(temp)\n",
        "        relu = Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same',kernel_regularizer=l2(weight_decay))(relu)\n",
        "\n",
        "        if dropout_rate>0:\n",
        "          Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
        "       \n",
        "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OOP6IPsGhBwb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def add_transition(input, num_filter, dropout_rate):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same',kernel_regularizer=l2(weight_decay))(relu)\n",
        "    if dropout_rate>0:\n",
        "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    \n",
        "    return avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0RaKFpubhDIC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    flat = Flatten()(AvgPooling)\n",
        "    output = Dense(num_classes, activation='softmax')(flat)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "anPCpQWhhGb7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input = Input(shape=(img_height, img_width, channel,))\n",
        "First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
        "\n",
        "First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate,l*2)\n",
        "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate,l)\n",
        "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate,l*2)\n",
        "Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Fourth_Block = add_denseblock(Third_Transition, num_filter, dropout_rate,l)\n",
        "\n",
        "output = output_layer(Fourth_Block)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1kFh7pdxhNtT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 15028
        },
        "outputId": "f77cbefe-9418-4213-bf4c-20b48bde603b"
      },
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 20)   540         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 20)   80          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 20)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_1 (SeparableCo (None, 32, 32, 10)   260         activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_2 (SeparableCo (None, 32, 32, 10)   130         separable_conv2d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 32, 32, 10)   0           separable_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 30)   0           conv2d_1[0][0]                   \n",
            "                                                                 dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 30)   120         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 30)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_3 (SeparableCo (None, 32, 32, 10)   390         activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_4 (SeparableCo (None, 32, 32, 10)   130         separable_conv2d_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 32, 32, 10)   0           separable_conv2d_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 40)   0           concatenate_1[0][0]              \n",
            "                                                                 dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 40)   160         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 40)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_5 (SeparableCo (None, 32, 32, 10)   520         activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_6 (SeparableCo (None, 32, 32, 10)   130         separable_conv2d_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 32, 32, 10)   0           separable_conv2d_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 32, 50)   0           concatenate_2[0][0]              \n",
            "                                                                 dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 50)   200         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 50)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_7 (SeparableCo (None, 32, 32, 10)   650         activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_8 (SeparableCo (None, 32, 32, 10)   130         separable_conv2d_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 32, 32, 10)   0           separable_conv2d_8[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 32, 32, 60)   0           concatenate_3[0][0]              \n",
            "                                                                 dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 60)   240         concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 60)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_9 (SeparableCo (None, 32, 32, 10)   780         activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_10 (SeparableC (None, 32, 32, 10)   130         separable_conv2d_9[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 32, 32, 10)   0           separable_conv2d_10[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 32, 32, 70)   0           concatenate_4[0][0]              \n",
            "                                                                 dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 70)   280         concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 70)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_11 (SeparableC (None, 32, 32, 10)   910         activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_12 (SeparableC (None, 32, 32, 10)   130         separable_conv2d_11[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 32, 32, 10)   0           separable_conv2d_12[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 32, 32, 80)   0           concatenate_5[0][0]              \n",
            "                                                                 dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 80)   320         concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 80)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_13 (SeparableC (None, 32, 32, 10)   1040        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_14 (SeparableC (None, 32, 32, 10)   130         separable_conv2d_13[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 32, 32, 10)   0           separable_conv2d_14[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 32, 32, 90)   0           concatenate_6[0][0]              \n",
            "                                                                 dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 90)   360         concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 90)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_15 (SeparableC (None, 32, 32, 10)   1170        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_16 (SeparableC (None, 32, 32, 10)   130         separable_conv2d_15[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 32, 32, 10)   0           separable_conv2d_16[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 32, 32, 100)  0           concatenate_7[0][0]              \n",
            "                                                                 dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 100)  400         concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 100)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_17 (SeparableC (None, 32, 32, 10)   1300        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_18 (SeparableC (None, 32, 32, 10)   130         separable_conv2d_17[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 32, 32, 10)   0           separable_conv2d_18[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 32, 32, 110)  0           concatenate_8[0][0]              \n",
            "                                                                 dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 110)  440         concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 110)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_19 (SeparableC (None, 32, 32, 10)   1430        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_20 (SeparableC (None, 32, 32, 10)   130         separable_conv2d_19[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 32, 32, 10)   0           separable_conv2d_20[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 32, 32, 120)  0           concatenate_9[0][0]              \n",
            "                                                                 dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 120)  480         concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 120)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_21 (SeparableC (None, 32, 32, 10)   1560        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_22 (SeparableC (None, 32, 32, 10)   130         separable_conv2d_21[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 32, 32, 10)   0           separable_conv2d_22[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 32, 32, 130)  0           concatenate_10[0][0]             \n",
            "                                                                 dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 130)  520         concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 130)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_23 (SeparableC (None, 32, 32, 10)   1690        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_24 (SeparableC (None, 32, 32, 10)   130         separable_conv2d_23[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 32, 32, 10)   0           separable_conv2d_24[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 32, 32, 140)  0           concatenate_11[0][0]             \n",
            "                                                                 dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 32, 32, 140)  560         concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 32, 32, 140)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_25 (SeparableC (None, 32, 32, 10)   1820        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_26 (SeparableC (None, 32, 32, 10)   130         separable_conv2d_25[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 32, 32, 10)   0           separable_conv2d_26[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 32, 32, 150)  0           concatenate_12[0][0]             \n",
            "                                                                 dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 32, 32, 150)  600         concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 32, 32, 150)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_27 (SeparableC (None, 32, 32, 10)   1950        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_28 (SeparableC (None, 32, 32, 10)   130         separable_conv2d_27[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 32, 32, 10)   0           separable_conv2d_28[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 32, 32, 160)  0           concatenate_13[0][0]             \n",
            "                                                                 dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 32, 32, 160)  640         concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 32, 32, 160)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_29 (SeparableC (None, 32, 32, 10)   2080        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_30 (SeparableC (None, 32, 32, 10)   130         separable_conv2d_29[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 32, 32, 10)   0           separable_conv2d_30[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 32, 32, 170)  0           concatenate_14[0][0]             \n",
            "                                                                 dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 32, 32, 170)  680         concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 32, 32, 170)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_31 (SeparableC (None, 32, 32, 10)   2210        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_32 (SeparableC (None, 32, 32, 10)   130         separable_conv2d_31[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 32, 32, 10)   0           separable_conv2d_32[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 32, 32, 180)  0           concatenate_15[0][0]             \n",
            "                                                                 dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 32, 32, 180)  720         concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 32, 32, 180)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 10)   1800        activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 32, 32, 10)   0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 10)   0           dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 10)   40          average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 10)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_33 (SeparableC (None, 16, 16, 10)   130         activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_34 (SeparableC (None, 16, 16, 10)   130         separable_conv2d_33[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 16, 16, 10)   0           separable_conv2d_34[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 16, 16, 20)   0           average_pooling2d_1[0][0]        \n",
            "                                                                 dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 20)   80          concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 20)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_35 (SeparableC (None, 16, 16, 10)   260         activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_36 (SeparableC (None, 16, 16, 10)   130         separable_conv2d_35[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_19 (Dropout)            (None, 16, 16, 10)   0           separable_conv2d_36[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 16, 16, 30)   0           concatenate_17[0][0]             \n",
            "                                                                 dropout_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 30)   120         concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 30)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_37 (SeparableC (None, 16, 16, 10)   390         activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_38 (SeparableC (None, 16, 16, 10)   130         separable_conv2d_37[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_20 (Dropout)            (None, 16, 16, 10)   0           separable_conv2d_38[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 16, 16, 40)   0           concatenate_18[0][0]             \n",
            "                                                                 dropout_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 40)   160         concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 40)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_39 (SeparableC (None, 16, 16, 10)   520         activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_40 (SeparableC (None, 16, 16, 10)   130         separable_conv2d_39[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_21 (Dropout)            (None, 16, 16, 10)   0           separable_conv2d_40[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_20 (Concatenate)    (None, 16, 16, 50)   0           concatenate_19[0][0]             \n",
            "                                                                 dropout_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 50)   200         concatenate_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 50)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_41 (SeparableC (None, 16, 16, 10)   650         activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_42 (SeparableC (None, 16, 16, 10)   130         separable_conv2d_41[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_22 (Dropout)            (None, 16, 16, 10)   0           separable_conv2d_42[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_21 (Concatenate)    (None, 16, 16, 60)   0           concatenate_20[0][0]             \n",
            "                                                                 dropout_22[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 60)   240         concatenate_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 60)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_43 (SeparableC (None, 16, 16, 10)   780         activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_44 (SeparableC (None, 16, 16, 10)   130         separable_conv2d_43[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_23 (Dropout)            (None, 16, 16, 10)   0           separable_conv2d_44[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_22 (Concatenate)    (None, 16, 16, 70)   0           concatenate_21[0][0]             \n",
            "                                                                 dropout_23[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 70)   280         concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 70)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_45 (SeparableC (None, 16, 16, 10)   910         activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_46 (SeparableC (None, 16, 16, 10)   130         separable_conv2d_45[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_24 (Dropout)            (None, 16, 16, 10)   0           separable_conv2d_46[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_23 (Concatenate)    (None, 16, 16, 80)   0           concatenate_22[0][0]             \n",
            "                                                                 dropout_24[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 80)   320         concatenate_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 80)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_47 (SeparableC (None, 16, 16, 10)   1040        activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_48 (SeparableC (None, 16, 16, 10)   130         separable_conv2d_47[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_25 (Dropout)            (None, 16, 16, 10)   0           separable_conv2d_48[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, 16, 16, 90)   0           concatenate_23[0][0]             \n",
            "                                                                 dropout_25[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 16, 16, 90)   360         concatenate_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 16, 16, 90)   0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_49 (SeparableC (None, 16, 16, 10)   1170        activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_50 (SeparableC (None, 16, 16, 10)   130         separable_conv2d_49[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_26 (Dropout)            (None, 16, 16, 10)   0           separable_conv2d_50[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_25 (Concatenate)    (None, 16, 16, 100)  0           concatenate_24[0][0]             \n",
            "                                                                 dropout_26[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 100)  400         concatenate_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 100)  0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_51 (SeparableC (None, 16, 16, 10)   1300        activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_52 (SeparableC (None, 16, 16, 10)   130         separable_conv2d_51[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_27 (Dropout)            (None, 16, 16, 10)   0           separable_conv2d_52[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_26 (Concatenate)    (None, 16, 16, 110)  0           concatenate_25[0][0]             \n",
            "                                                                 dropout_27[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 110)  440         concatenate_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 110)  0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_53 (SeparableC (None, 16, 16, 10)   1430        activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_54 (SeparableC (None, 16, 16, 10)   130         separable_conv2d_53[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_28 (Dropout)            (None, 16, 16, 10)   0           separable_conv2d_54[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_27 (Concatenate)    (None, 16, 16, 120)  0           concatenate_26[0][0]             \n",
            "                                                                 dropout_28[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 16, 16, 120)  480         concatenate_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 16, 16, 120)  0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_55 (SeparableC (None, 16, 16, 10)   1560        activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_56 (SeparableC (None, 16, 16, 10)   130         separable_conv2d_55[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_29 (Dropout)            (None, 16, 16, 10)   0           separable_conv2d_56[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_28 (Concatenate)    (None, 16, 16, 130)  0           concatenate_27[0][0]             \n",
            "                                                                 dropout_29[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 16, 16, 130)  520         concatenate_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 16, 16, 130)  0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_57 (SeparableC (None, 16, 16, 10)   1690        activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_58 (SeparableC (None, 16, 16, 10)   130         separable_conv2d_57[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_30 (Dropout)            (None, 16, 16, 10)   0           separable_conv2d_58[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_29 (Concatenate)    (None, 16, 16, 140)  0           concatenate_28[0][0]             \n",
            "                                                                 dropout_30[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 16, 16, 140)  560         concatenate_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 16, 16, 140)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_59 (SeparableC (None, 16, 16, 10)   1820        activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_60 (SeparableC (None, 16, 16, 10)   130         separable_conv2d_59[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_31 (Dropout)            (None, 16, 16, 10)   0           separable_conv2d_60[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_30 (Concatenate)    (None, 16, 16, 150)  0           concatenate_29[0][0]             \n",
            "                                                                 dropout_31[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 16, 16, 150)  600         concatenate_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 16, 16, 150)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_61 (SeparableC (None, 16, 16, 10)   1950        activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_62 (SeparableC (None, 16, 16, 10)   130         separable_conv2d_61[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_32 (Dropout)            (None, 16, 16, 10)   0           separable_conv2d_62[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_31 (Concatenate)    (None, 16, 16, 160)  0           concatenate_30[0][0]             \n",
            "                                                                 dropout_32[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 16, 16, 160)  640         concatenate_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 16, 16, 160)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_63 (SeparableC (None, 16, 16, 10)   2080        activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_64 (SeparableC (None, 16, 16, 10)   130         separable_conv2d_63[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_33 (Dropout)            (None, 16, 16, 10)   0           separable_conv2d_64[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_32 (Concatenate)    (None, 16, 16, 170)  0           concatenate_31[0][0]             \n",
            "                                                                 dropout_33[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 16, 16, 170)  680         concatenate_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 16, 16, 170)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 16, 16, 10)   1700        activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_34 (Dropout)            (None, 16, 16, 10)   0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 8, 8, 10)     0           dropout_34[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 8, 8, 10)     40          average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 8, 8, 10)     0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_65 (SeparableC (None, 8, 8, 10)     130         activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_66 (SeparableC (None, 8, 8, 10)     130         separable_conv2d_65[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_35 (Dropout)            (None, 8, 8, 10)     0           separable_conv2d_66[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_33 (Concatenate)    (None, 8, 8, 20)     0           average_pooling2d_2[0][0]        \n",
            "                                                                 dropout_35[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 8, 8, 20)     80          concatenate_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 8, 8, 20)     0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_67 (SeparableC (None, 8, 8, 10)     260         activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_68 (SeparableC (None, 8, 8, 10)     130         separable_conv2d_67[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_36 (Dropout)            (None, 8, 8, 10)     0           separable_conv2d_68[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_34 (Concatenate)    (None, 8, 8, 30)     0           concatenate_33[0][0]             \n",
            "                                                                 dropout_36[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 8, 8, 30)     120         concatenate_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 8, 8, 30)     0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_69 (SeparableC (None, 8, 8, 10)     390         activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_70 (SeparableC (None, 8, 8, 10)     130         separable_conv2d_69[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 8, 8, 10)     0           separable_conv2d_70[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_35 (Concatenate)    (None, 8, 8, 40)     0           concatenate_34[0][0]             \n",
            "                                                                 dropout_37[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 8, 8, 40)     160         concatenate_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 8, 8, 40)     0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_71 (SeparableC (None, 8, 8, 10)     520         activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_72 (SeparableC (None, 8, 8, 10)     130         separable_conv2d_71[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_38 (Dropout)            (None, 8, 8, 10)     0           separable_conv2d_72[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_36 (Concatenate)    (None, 8, 8, 50)     0           concatenate_35[0][0]             \n",
            "                                                                 dropout_38[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 8, 8, 50)     200         concatenate_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 8, 8, 50)     0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_73 (SeparableC (None, 8, 8, 10)     650         activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_74 (SeparableC (None, 8, 8, 10)     130         separable_conv2d_73[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_39 (Dropout)            (None, 8, 8, 10)     0           separable_conv2d_74[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_37 (Concatenate)    (None, 8, 8, 60)     0           concatenate_36[0][0]             \n",
            "                                                                 dropout_39[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 8, 8, 60)     240         concatenate_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 8, 8, 60)     0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_75 (SeparableC (None, 8, 8, 10)     780         activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_76 (SeparableC (None, 8, 8, 10)     130         separable_conv2d_75[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_40 (Dropout)            (None, 8, 8, 10)     0           separable_conv2d_76[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_38 (Concatenate)    (None, 8, 8, 70)     0           concatenate_37[0][0]             \n",
            "                                                                 dropout_40[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 8, 8, 70)     280         concatenate_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 8, 8, 70)     0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_77 (SeparableC (None, 8, 8, 10)     910         activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_78 (SeparableC (None, 8, 8, 10)     130         separable_conv2d_77[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_41 (Dropout)            (None, 8, 8, 10)     0           separable_conv2d_78[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_39 (Concatenate)    (None, 8, 8, 80)     0           concatenate_38[0][0]             \n",
            "                                                                 dropout_41[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 8, 8, 80)     320         concatenate_39[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 8, 8, 80)     0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_79 (SeparableC (None, 8, 8, 10)     1040        activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_80 (SeparableC (None, 8, 8, 10)     130         separable_conv2d_79[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_42 (Dropout)            (None, 8, 8, 10)     0           separable_conv2d_80[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_40 (Concatenate)    (None, 8, 8, 90)     0           concatenate_39[0][0]             \n",
            "                                                                 dropout_42[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 8, 8, 90)     360         concatenate_40[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 8, 8, 90)     0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_81 (SeparableC (None, 8, 8, 10)     1170        activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_82 (SeparableC (None, 8, 8, 10)     130         separable_conv2d_81[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_43 (Dropout)            (None, 8, 8, 10)     0           separable_conv2d_82[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_41 (Concatenate)    (None, 8, 8, 100)    0           concatenate_40[0][0]             \n",
            "                                                                 dropout_43[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 8, 8, 100)    400         concatenate_41[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 8, 8, 100)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_83 (SeparableC (None, 8, 8, 10)     1300        activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_84 (SeparableC (None, 8, 8, 10)     130         separable_conv2d_83[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_44 (Dropout)            (None, 8, 8, 10)     0           separable_conv2d_84[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_42 (Concatenate)    (None, 8, 8, 110)    0           concatenate_41[0][0]             \n",
            "                                                                 dropout_44[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 8, 8, 110)    440         concatenate_42[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 8, 8, 110)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_85 (SeparableC (None, 8, 8, 10)     1430        activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_86 (SeparableC (None, 8, 8, 10)     130         separable_conv2d_85[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_45 (Dropout)            (None, 8, 8, 10)     0           separable_conv2d_86[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_43 (Concatenate)    (None, 8, 8, 120)    0           concatenate_42[0][0]             \n",
            "                                                                 dropout_45[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 8, 8, 120)    480         concatenate_43[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 8, 8, 120)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_87 (SeparableC (None, 8, 8, 10)     1560        activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_88 (SeparableC (None, 8, 8, 10)     130         separable_conv2d_87[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_46 (Dropout)            (None, 8, 8, 10)     0           separable_conv2d_88[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_44 (Concatenate)    (None, 8, 8, 130)    0           concatenate_43[0][0]             \n",
            "                                                                 dropout_46[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 8, 8, 130)    520         concatenate_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 8, 8, 130)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_89 (SeparableC (None, 8, 8, 10)     1690        activation_47[0][0]              \n",
            "__________________________________________________________________________________________________"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "separable_conv2d_90 (SeparableC (None, 8, 8, 10)     130         separable_conv2d_89[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_47 (Dropout)            (None, 8, 8, 10)     0           separable_conv2d_90[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_45 (Concatenate)    (None, 8, 8, 140)    0           concatenate_44[0][0]             \n",
            "                                                                 dropout_47[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 8, 8, 140)    560         concatenate_45[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 8, 8, 140)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_91 (SeparableC (None, 8, 8, 10)     1820        activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_92 (SeparableC (None, 8, 8, 10)     130         separable_conv2d_91[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_48 (Dropout)            (None, 8, 8, 10)     0           separable_conv2d_92[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_46 (Concatenate)    (None, 8, 8, 150)    0           concatenate_45[0][0]             \n",
            "                                                                 dropout_48[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 8, 8, 150)    600         concatenate_46[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 8, 8, 150)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_93 (SeparableC (None, 8, 8, 10)     1950        activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_94 (SeparableC (None, 8, 8, 10)     130         separable_conv2d_93[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_49 (Dropout)            (None, 8, 8, 10)     0           separable_conv2d_94[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_47 (Concatenate)    (None, 8, 8, 160)    0           concatenate_46[0][0]             \n",
            "                                                                 dropout_49[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 8, 8, 160)    640         concatenate_47[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 8, 8, 160)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_95 (SeparableC (None, 8, 8, 10)     2080        activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_96 (SeparableC (None, 8, 8, 10)     130         separable_conv2d_95[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_50 (Dropout)            (None, 8, 8, 10)     0           separable_conv2d_96[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_48 (Concatenate)    (None, 8, 8, 170)    0           concatenate_47[0][0]             \n",
            "                                                                 dropout_50[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 8, 8, 170)    680         concatenate_48[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 8, 8, 170)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 8, 8, 10)     1700        activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_51 (Dropout)            (None, 8, 8, 10)     0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 4, 4, 10)     0           dropout_51[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 4, 4, 10)     40          average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 4, 4, 10)     0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_97 (SeparableC (None, 4, 4, 10)     130         activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_98 (SeparableC (None, 4, 4, 10)     130         separable_conv2d_97[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_52 (Dropout)            (None, 4, 4, 10)     0           separable_conv2d_98[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_49 (Concatenate)    (None, 4, 4, 20)     0           average_pooling2d_3[0][0]        \n",
            "                                                                 dropout_52[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 4, 4, 20)     80          concatenate_49[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 4, 4, 20)     0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_99 (SeparableC (None, 4, 4, 10)     260         activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_100 (Separable (None, 4, 4, 10)     130         separable_conv2d_99[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_53 (Dropout)            (None, 4, 4, 10)     0           separable_conv2d_100[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_50 (Concatenate)    (None, 4, 4, 30)     0           concatenate_49[0][0]             \n",
            "                                                                 dropout_53[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 4, 4, 30)     120         concatenate_50[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 4, 4, 30)     0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_101 (Separable (None, 4, 4, 10)     390         activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_102 (Separable (None, 4, 4, 10)     130         separable_conv2d_101[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_54 (Dropout)            (None, 4, 4, 10)     0           separable_conv2d_102[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_51 (Concatenate)    (None, 4, 4, 40)     0           concatenate_50[0][0]             \n",
            "                                                                 dropout_54[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 4, 4, 40)     160         concatenate_51[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 4, 4, 40)     0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_103 (Separable (None, 4, 4, 10)     520         activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_104 (Separable (None, 4, 4, 10)     130         separable_conv2d_103[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_55 (Dropout)            (None, 4, 4, 10)     0           separable_conv2d_104[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_52 (Concatenate)    (None, 4, 4, 50)     0           concatenate_51[0][0]             \n",
            "                                                                 dropout_55[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 4, 4, 50)     200         concatenate_52[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 4, 4, 50)     0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_105 (Separable (None, 4, 4, 10)     650         activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_106 (Separable (None, 4, 4, 10)     130         separable_conv2d_105[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_56 (Dropout)            (None, 4, 4, 10)     0           separable_conv2d_106[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_53 (Concatenate)    (None, 4, 4, 60)     0           concatenate_52[0][0]             \n",
            "                                                                 dropout_56[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 4, 4, 60)     240         concatenate_53[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 4, 4, 60)     0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_107 (Separable (None, 4, 4, 10)     780         activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_108 (Separable (None, 4, 4, 10)     130         separable_conv2d_107[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_57 (Dropout)            (None, 4, 4, 10)     0           separable_conv2d_108[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_54 (Concatenate)    (None, 4, 4, 70)     0           concatenate_53[0][0]             \n",
            "                                                                 dropout_57[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 4, 4, 70)     280         concatenate_54[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 4, 4, 70)     0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_109 (Separable (None, 4, 4, 10)     910         activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_110 (Separable (None, 4, 4, 10)     130         separable_conv2d_109[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_58 (Dropout)            (None, 4, 4, 10)     0           separable_conv2d_110[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_55 (Concatenate)    (None, 4, 4, 80)     0           concatenate_54[0][0]             \n",
            "                                                                 dropout_58[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 4, 4, 80)     320         concatenate_55[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 4, 4, 80)     0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_111 (Separable (None, 4, 4, 10)     1040        activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_112 (Separable (None, 4, 4, 10)     130         separable_conv2d_111[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_59 (Dropout)            (None, 4, 4, 10)     0           separable_conv2d_112[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_56 (Concatenate)    (None, 4, 4, 90)     0           concatenate_55[0][0]             \n",
            "                                                                 dropout_59[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 4, 4, 90)     360         concatenate_56[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 4, 4, 90)     0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_113 (Separable (None, 4, 4, 10)     1170        activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_114 (Separable (None, 4, 4, 10)     130         separable_conv2d_113[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_60 (Dropout)            (None, 4, 4, 10)     0           separable_conv2d_114[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_57 (Concatenate)    (None, 4, 4, 100)    0           concatenate_56[0][0]             \n",
            "                                                                 dropout_60[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 4, 4, 100)    400         concatenate_57[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 4, 4, 100)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_115 (Separable (None, 4, 4, 10)     1300        activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_116 (Separable (None, 4, 4, 10)     130         separable_conv2d_115[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_61 (Dropout)            (None, 4, 4, 10)     0           separable_conv2d_116[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_58 (Concatenate)    (None, 4, 4, 110)    0           concatenate_57[0][0]             \n",
            "                                                                 dropout_61[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 4, 4, 110)    440         concatenate_58[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 4, 4, 110)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_117 (Separable (None, 4, 4, 10)     1430        activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_118 (Separable (None, 4, 4, 10)     130         separable_conv2d_117[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_62 (Dropout)            (None, 4, 4, 10)     0           separable_conv2d_118[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_59 (Concatenate)    (None, 4, 4, 120)    0           concatenate_58[0][0]             \n",
            "                                                                 dropout_62[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 4, 4, 120)    480         concatenate_59[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 4, 4, 120)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_119 (Separable (None, 4, 4, 10)     1560        activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_120 (Separable (None, 4, 4, 10)     130         separable_conv2d_119[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_63 (Dropout)            (None, 4, 4, 10)     0           separable_conv2d_120[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_60 (Concatenate)    (None, 4, 4, 130)    0           concatenate_59[0][0]             \n",
            "                                                                 dropout_63[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 4, 4, 130)    520         concatenate_60[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 4, 4, 130)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_121 (Separable (None, 4, 4, 10)     1690        activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_122 (Separable (None, 4, 4, 10)     130         separable_conv2d_121[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_64 (Dropout)            (None, 4, 4, 10)     0           separable_conv2d_122[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_61 (Concatenate)    (None, 4, 4, 140)    0           concatenate_60[0][0]             \n",
            "                                                                 dropout_64[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 4, 4, 140)    560         concatenate_61[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 4, 4, 140)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_123 (Separable (None, 4, 4, 10)     1820        activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_124 (Separable (None, 4, 4, 10)     130         separable_conv2d_123[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_65 (Dropout)            (None, 4, 4, 10)     0           separable_conv2d_124[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_62 (Concatenate)    (None, 4, 4, 150)    0           concatenate_61[0][0]             \n",
            "                                                                 dropout_65[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 4, 4, 150)    600         concatenate_62[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 4, 4, 150)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_125 (Separable (None, 4, 4, 10)     1950        activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_126 (Separable (None, 4, 4, 10)     130         separable_conv2d_125[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_66 (Dropout)            (None, 4, 4, 10)     0           separable_conv2d_126[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_63 (Concatenate)    (None, 4, 4, 160)    0           concatenate_62[0][0]             \n",
            "                                                                 dropout_66[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 4, 4, 160)    640         concatenate_63[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 4, 4, 160)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_127 (Separable (None, 4, 4, 10)     2080        activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_128 (Separable (None, 4, 4, 10)     130         separable_conv2d_127[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_67 (Dropout)            (None, 4, 4, 10)     0           separable_conv2d_128[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_64 (Concatenate)    (None, 4, 4, 170)    0           concatenate_63[0][0]             \n",
            "                                                                 dropout_67[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 4, 4, 170)    680         concatenate_64[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 4, 4, 170)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 2, 2, 170)    0           activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 680)          0           average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           6810        flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 118,830\n",
            "Trainable params: 106,250\n",
            "Non-trainable params: 12,580\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b4XOsW3ahSkL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# determine Loss function and Optimizer\n",
        "#from utils import GDriveSync\n",
        "#downloader=GDriveSync()\n",
        "#filename='DNS_SID_0.8357.h5'\n",
        "#drive_file_path=downloader.find_items(filename)[0]\n",
        "#downloader.download_file_to_folder(drive_file_path,filename)\n",
        "#model.load_weights(filename)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "crhGk7kEhXAz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2621
        },
        "outputId": "77adf548-01e1-4eed-9582-ff57e36138dd"
      },
      "cell_type": "code",
      "source": [
        "from time import time\n",
        "t0 = time()\n",
        "\n",
        "def compare(best, new):\n",
        "  return best.losses['val_acc'] < new.losses['val_acc']\n",
        "\n",
        "def path(new):\n",
        "  if new.losses['val_acc'] > 0.8:\n",
        "    return 'DNS_SID_%s.h5' % new.losses['val_acc']\n",
        "\n",
        "callbacks = cb = [\n",
        "      utils.GDriveCheckpointer(compare,path),\n",
        "      keras.callbacks.TensorBoard(log_dir=os.path.join(utils.LOG_DIR,'DNS_SID'))\n",
        "]\n",
        "\n",
        "\n",
        "#model.fit(X_train, Y_train, batch_size=32, epochs=10, verbose=1,validation_data=(X_test, Y_test),validation_split=0.33, callbacks=callbacks)\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=50,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test),callbacks=callbacks)\n",
        "\n",
        "print('Time elapsed: %.2fs' % (time()-t0))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 271s 5ms/step - loss: 1.6947 - acc: 0.3584 - val_loss: 1.6588 - val_acc: 0.4252\n",
            "Skipping upload because path function returned no path.\n",
            "Epoch 2/50\n",
            "16000/50000 [========>.....................] - ETA: 2:39 - loss: 1.3855 - acc: 0.4881"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 252s 5ms/step - loss: 1.3090 - acc: 0.5240 - val_loss: 1.2729 - val_acc: 0.5439\n",
            "Skipping upload because path function returned no path.\n",
            "Epoch 3/50\n",
            "35328/50000 [====================>.........] - ETA: 1:08 - loss: 1.1372 - acc: 0.5902"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 252s 5ms/step - loss: 1.1261 - acc: 0.5948 - val_loss: 1.1812 - val_acc: 0.5978\n",
            "Skipping upload because path function returned no path.\n",
            "Epoch 4/50\n",
            "41216/50000 [=======================>......] - ETA: 41s - loss: 1.0317 - acc: 0.6308"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 252s 5ms/step - loss: 1.0270 - acc: 0.6332 - val_loss: 1.3305 - val_acc: 0.5656\n",
            "No improvement.\n",
            "Epoch 5/50\n",
            "50000/50000 [==============================] - 251s 5ms/step - loss: 0.9661 - acc: 0.6578 - val_loss: 1.4669 - val_acc: 0.5743\n",
            "No improvement.\n",
            "Epoch 6/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 250s 5ms/step - loss: 0.9212 - acc: 0.6729 - val_loss: 1.8483 - val_acc: 0.5187\n",
            "No improvement.\n",
            "Epoch 7/50\n",
            "35712/50000 [====================>.........] - ETA: 1:06 - loss: 0.8911 - acc: 0.6833"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 250s 5ms/step - loss: 0.8851 - acc: 0.6856 - val_loss: 0.9628 - val_acc: 0.6755\n",
            "Skipping upload because path function returned no path.\n",
            "Epoch 8/50\n",
            "41344/50000 [=======================>......] - ETA: 40s - loss: 0.8550 - acc: 0.6971"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 250s 5ms/step - loss: 0.8518 - acc: 0.6980 - val_loss: 1.0776 - val_acc: 0.6348\n",
            "No improvement.\n",
            "Epoch 9/50\n",
            "50000/50000 [==============================] - 251s 5ms/step - loss: 0.8177 - acc: 0.7145 - val_loss: 1.2061 - val_acc: 0.6325\n",
            "No improvement.\n",
            "Epoch 10/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 251s 5ms/step - loss: 0.7916 - acc: 0.7210 - val_loss: 1.1465 - val_acc: 0.6568\n",
            "No improvement.\n",
            "Epoch 11/50\n",
            "35456/50000 [====================>.........] - ETA: 1:08 - loss: 0.7694 - acc: 0.7321"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 252s 5ms/step - loss: 0.7691 - acc: 0.7311 - val_loss: 1.0966 - val_acc: 0.6613\n",
            "No improvement.\n",
            "Epoch 12/50\n",
            "48000/50000 [===========================>..] - ETA: 9s - loss: 0.7375 - acc: 0.7410"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 251s 5ms/step - loss: 0.7373 - acc: 0.7409 - val_loss: 1.1098 - val_acc: 0.6505\n",
            "No improvement.\n",
            "Epoch 13/50\n",
            "50000/50000 [==============================] - 251s 5ms/step - loss: 0.7197 - acc: 0.7487 - val_loss: 0.8544 - val_acc: 0.7125\n",
            "Skipping upload because path function returned no path.\n",
            "Epoch 14/50\n",
            " 1152/50000 [..............................] - ETA: 3:49 - loss: 0.6831 - acc: 0.7569"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 252s 5ms/step - loss: 0.6977 - acc: 0.7573 - val_loss: 0.8929 - val_acc: 0.7213\n",
            "Skipping upload because path function returned no path.\n",
            "Epoch 15/50\n",
            "30720/50000 [=================>............] - ETA: 1:30 - loss: 0.6773 - acc: 0.7631"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 252s 5ms/step - loss: 0.6804 - acc: 0.7630 - val_loss: 0.8844 - val_acc: 0.7162\n",
            "No improvement.\n",
            "Epoch 16/50\n",
            "46336/50000 [==========================>...] - ETA: 17s - loss: 0.6615 - acc: 0.7713"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 252s 5ms/step - loss: 0.6606 - acc: 0.7716 - val_loss: 0.7532 - val_acc: 0.7528\n",
            "Skipping upload because path function returned no path.\n",
            "Epoch 17/50\n",
            "44416/50000 [=========================>....] - ETA: 26s - loss: 0.6487 - acc: 0.7748"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 252s 5ms/step - loss: 0.6475 - acc: 0.7759 - val_loss: 0.9350 - val_acc: 0.7051\n",
            "No improvement.\n",
            "Epoch 18/50\n",
            "50000/50000 [==============================] - 252s 5ms/step - loss: 0.6296 - acc: 0.7809 - val_loss: 0.8368 - val_acc: 0.7314\n",
            "No improvement.\n",
            "Epoch 19/50\n",
            "  512/50000 [..............................] - ETA: 3:51 - loss: 0.5783 - acc: 0.7891"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 252s 5ms/step - loss: 0.6176 - acc: 0.7854 - val_loss: 0.8088 - val_acc: 0.7450\n",
            "No improvement.\n",
            "Epoch 20/50\n",
            "35584/50000 [====================>.........] - ETA: 1:07 - loss: 0.5990 - acc: 0.7924"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 252s 5ms/step - loss: 0.5990 - acc: 0.7926 - val_loss: 0.7619 - val_acc: 0.7560\n",
            "Skipping upload because path function returned no path.\n",
            "Epoch 21/50\n",
            "41216/50000 [=======================>......] - ETA: 41s - loss: 0.5921 - acc: 0.7961"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 252s 5ms/step - loss: 0.5930 - acc: 0.7965 - val_loss: 0.7270 - val_acc: 0.7691\n",
            "Skipping upload because path function returned no path.\n",
            "Epoch 22/50\n",
            "42880/50000 [========================>.....] - ETA: 33s - loss: 0.5806 - acc: 0.8008"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 252s 5ms/step - loss: 0.5808 - acc: 0.8003 - val_loss: 0.7539 - val_acc: 0.7666\n",
            "No improvement.\n",
            "Epoch 23/50\n",
            "50000/50000 [==============================] - 252s 5ms/step - loss: 0.5725 - acc: 0.8025 - val_loss: 0.7656 - val_acc: 0.7574\n",
            "No improvement.\n",
            "Epoch 24/50\n",
            "  256/50000 [..............................] - ETA: 3:55 - loss: 0.5125 - acc: 0.8516"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 252s 5ms/step - loss: 0.5590 - acc: 0.8067 - val_loss: 0.8687 - val_acc: 0.7450\n",
            "No improvement.\n",
            "Epoch 25/50\n",
            "35584/50000 [====================>.........] - ETA: 1:07 - loss: 0.5459 - acc: 0.8110"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 252s 5ms/step - loss: 0.5507 - acc: 0.8083 - val_loss: 0.6636 - val_acc: 0.7816\n",
            "Skipping upload because path function returned no path.\n",
            "Epoch 26/50\n",
            "41216/50000 [=======================>......] - ETA: 41s - loss: 0.5363 - acc: 0.8142"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 252s 5ms/step - loss: 0.5389 - acc: 0.8130 - val_loss: 0.7783 - val_acc: 0.7711\n",
            "No improvement.\n",
            "Epoch 27/50\n",
            "50000/50000 [==============================] - 253s 5ms/step - loss: 0.5302 - acc: 0.8161 - val_loss: 0.8824 - val_acc: 0.7450\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "No improvement.\n",
            "Epoch 28/50\n",
            "50000/50000 [==============================] - 253s 5ms/step - loss: 0.5242 - acc: 0.8216 - val_loss: 0.7778 - val_acc: 0.7638\n",
            "No improvement.\n",
            "Epoch 29/50\n",
            "26496/50000 [==============>...............] - ETA: 1:50 - loss: 0.5144 - acc: 0.8223"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 253s 5ms/step - loss: 0.5200 - acc: 0.8206 - val_loss: 0.7683 - val_acc: 0.7678\n",
            "No improvement.\n",
            "Epoch 30/50\n",
            "44928/50000 [=========================>....] - ETA: 23s - loss: 0.5066 - acc: 0.8247"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 252s 5ms/step - loss: 0.5080 - acc: 0.8247 - val_loss: 0.6945 - val_acc: 0.7845\n",
            "Skipping upload because path function returned no path.\n",
            "Epoch 31/50\n",
            "44032/50000 [=========================>....] - ETA: 28s - loss: 0.5049 - acc: 0.8264"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 252s 5ms/step - loss: 0.5037 - acc: 0.8266 - val_loss: 0.6393 - val_acc: 0.7981\n",
            "Skipping upload because path function returned no path.\n",
            "Epoch 32/50\n",
            "43776/50000 [=========================>....] - ETA: 29s - loss: 0.4883 - acc: 0.8319"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 253s 5ms/step - loss: 0.4926 - acc: 0.8306 - val_loss: 1.2066 - val_acc: 0.6839\n",
            "No improvement.\n",
            "Epoch 33/50\n",
            "50000/50000 [==============================] - 253s 5ms/step - loss: 0.4885 - acc: 0.8315 - val_loss: 0.6459 - val_acc: 0.7944\n",
            "No improvement.\n",
            "Epoch 34/50\n",
            "  384/50000 [..............................] - ETA: 3:53 - loss: 0.5059 - acc: 0.8411"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 253s 5ms/step - loss: 0.4830 - acc: 0.8332 - val_loss: 0.6475 - val_acc: 0.7927\n",
            "No improvement.\n",
            "Epoch 35/50\n",
            "35584/50000 [====================>.........] - ETA: 1:08 - loss: 0.4766 - acc: 0.8352"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 253s 5ms/step - loss: 0.4746 - acc: 0.8364 - val_loss: 0.6864 - val_acc: 0.7936\n",
            "No improvement.\n",
            "Epoch 36/50\n",
            "48128/50000 [===========================>..] - ETA: 8s - loss: 0.4725 - acc: 0.8376"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 253s 5ms/step - loss: 0.4726 - acc: 0.8376 - val_loss: 0.7801 - val_acc: 0.7758\n",
            "No improvement.\n",
            "Epoch 37/50\n",
            "50000/50000 [==============================] - 253s 5ms/step - loss: 0.4655 - acc: 0.8410 - val_loss: 0.6911 - val_acc: 0.7897\n",
            "No improvement.\n",
            "Epoch 38/50\n",
            " 1408/50000 [..............................] - ETA: 3:48 - loss: 0.4784 - acc: 0.8381"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 253s 5ms/step - loss: 0.4629 - acc: 0.8410 - val_loss: 0.6888 - val_acc: 0.7994\n",
            "Skipping upload because path function returned no path.\n",
            "Epoch 39/50\n",
            "30848/50000 [=================>............] - ETA: 1:30 - loss: 0.4571 - acc: 0.8424"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 253s 5ms/step - loss: 0.4614 - acc: 0.8409 - val_loss: 0.7040 - val_acc: 0.7918\n",
            "No improvement.\n",
            "Epoch 40/50\n",
            "46464/50000 [==========================>...] - ETA: 16s - loss: 0.4503 - acc: 0.8435"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 252s 5ms/step - loss: 0.4517 - acc: 0.8432 - val_loss: 0.7082 - val_acc: 0.7821\n",
            "No improvement.\n",
            "Epoch 41/50\n",
            "50000/50000 [==============================] - 252s 5ms/step - loss: 0.4493 - acc: 0.8453 - val_loss: 0.9368 - val_acc: 0.7492\n",
            "No improvement.\n",
            "Epoch 42/50\n",
            " 1024/50000 [..............................] - ETA: 3:50 - loss: 0.4091 - acc: 0.8633"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 252s 5ms/step - loss: 0.4432 - acc: 0.8484 - val_loss: 0.7840 - val_acc: 0.7820\n",
            "No improvement.\n",
            "Epoch 43/50\n",
            "35840/50000 [====================>.........] - ETA: 1:06 - loss: 0.4345 - acc: 0.8490"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 252s 5ms/step - loss: 0.4397 - acc: 0.8473 - val_loss: 0.7427 - val_acc: 0.7849\n",
            "No improvement.\n",
            "Epoch 44/50\n",
            "48256/50000 [===========================>..] - ETA: 8s - loss: 0.4355 - acc: 0.8491"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 252s 5ms/step - loss: 0.4355 - acc: 0.8491 - val_loss: 0.7070 - val_acc: 0.7918\n",
            "No improvement.\n",
            "Epoch 45/50\n",
            "50000/50000 [==============================] - 252s 5ms/step - loss: 0.4332 - acc: 0.8498 - val_loss: 0.5968 - val_acc: 0.8205\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploading file DNS_SID_0.8205.h5 to folder Colab Notebooks: 100%|██████████| 100/100 [00:00<00:00, 101.94it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 46/50\n",
            "50000/50000 [==============================] - 252s 5ms/step - loss: 0.4261 - acc: 0.8524 - val_loss: 0.6284 - val_acc: 0.8126\n",
            "No improvement.\n",
            "Epoch 47/50\n",
            "31360/50000 [=================>............] - ETA: 1:27 - loss: 0.4211 - acc: 0.8578"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 252s 5ms/step - loss: 0.4211 - acc: 0.8563 - val_loss: 0.6129 - val_acc: 0.8157\n",
            "No improvement.\n",
            "Epoch 48/50\n",
            "46592/50000 [==========================>...] - ETA: 16s - loss: 0.4125 - acc: 0.8577"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 252s 5ms/step - loss: 0.4140 - acc: 0.8569 - val_loss: 0.6906 - val_acc: 0.7990\n",
            "No improvement.\n",
            "Epoch 49/50\n",
            "50000/50000 [==============================] - 252s 5ms/step - loss: 0.4136 - acc: 0.8570 - val_loss: 0.7122 - val_acc: 0.7905\n",
            "No improvement.\n",
            "Epoch 50/50\n",
            " 1024/50000 [..............................] - ETA: 3:50 - loss: 0.3792 - acc: 0.8672"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 252s 5ms/step - loss: 0.4105 - acc: 0.8589 - val_loss: 0.7692 - val_acc: 0.7816\n",
            "No improvement.\n",
            "Time elapsed: 12713.27s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZcWydmIVhZGr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c4c96290-14d2-4486-f22b-ddb735057af7"
      },
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 23s 2ms/step\n",
            "Test loss: 0.7691524684906006\n",
            "Test accuracy: 0.7816\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2yErLY8XiqE4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "outputId": "cdd6ff03-0092-4386-9074-521d500f20ae"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "accuracy = history.history['acc']\n",
        "val_accuracy = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(len(accuracy))\n",
        "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEHCAYAAACzy817AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ni3UB5wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f3921b04748>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEHCAYAAACzy817AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f3873272588>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "psZfrSKhjxQs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UE3lF6EH1r_L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "11d57af0-257a-4d0c-d5e3-990edcebc276"
      },
      "cell_type": "code",
      "source": [
        "# Save the trained weights in to .h5 format\n",
        "model.save_weights(\"DNST_model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ai-yZ2ED5AK1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('DNST_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}